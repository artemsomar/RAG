"""create chunk table

Revision ID: 9159ed20e205
Revises: 2c6e62fe0b30
Create Date: 2025-09-22 03:33:33.583133

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '9159ed20e205'
down_revision: Union[str, Sequence[str], None] = '2c6e62fe0b30'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('chunks',
    sa.Column('start_index', sa.BigInteger(), nullable=False),
    sa.Column('end_index', sa.BigInteger(), nullable=False),
    sa.Column('serial_idx', sa.Integer(), nullable=False),
    sa.Column('document_id', sa.BigInteger(), nullable=False),
    sa.Column('id', sa.BigInteger(), nullable=False),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], name='fk_embedded_chunks_document_id'),
    sa.PrimaryKeyConstraint('id')
    )
    op.drop_table('embedded_chunks')
    op.drop_table('tokenized_chunks')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('tokenized_chunks',
    sa.Column('tokens', postgresql.ARRAY(sa.INTEGER()), autoincrement=False, nullable=False),
    sa.Column('model', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('document_id', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('start_index', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('end_index', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('serial_idx', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], name=op.f('tokenized_chunks_document_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('tokenized_chunks_pkey'))
    )
    op.create_table('embedded_chunks',
    sa.Column('vector', postgresql.ARRAY(sa.DOUBLE_PRECISION(precision=53)), autoincrement=False, nullable=False),
    sa.Column('model', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('document_id', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('start_index', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('end_index', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('serial_idx', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], name=op.f('embedded_chunks_document_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('embedded_chunks_pkey'))
    )
    op.drop_table('chunks')
    # ### end Alembic commands ###
